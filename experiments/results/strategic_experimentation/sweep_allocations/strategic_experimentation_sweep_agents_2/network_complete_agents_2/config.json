{
  "args": {
    "num_episodes": 1,
    "horizon": 50,
    "hidden_dim": 256,
    "belief_dim": 256,
    "latent_dim": 256,
    "learning_rate": 0.001,
    "discount_factor": 0.0,
    "entropy_weight": 0.01,
    "kl_weight": 0.01,
    "buffer_capacity": 50,
    "batch_size": 8,
    "update_interval": 10,
    "use_gnn": true,
    "use_si": false,
    "si_importance": 10,
    "si_damping": 0.1,
    "si_exclude_final_layers": false,
    "continuous_actions": true,
    "device": "cpu",
    "output_dir": "results/strategic_experimentation/sweep_allocations",
    "exp_name": "strategic_experimentation_sweep_agents_2",
    "eval_only": false,
    "plot_internal_states": false,
    "plot_allocations": false,
    "use_tex": false,
    "save_model": false,
    "seed": 0,
    "network_type": "complete",
    "network_density": 0.5,
    "gnn_layers": 2,
    "attn_heads": 4,
    "temporal_window": 5
  },
  "theoretical_bounds": {
    "mpe_neutral": 0.0,
    "mpe_good_state": 0.0,
    "mpe_bad_state": 1.0
  },
  "environment": {
    "num_agents": 2,
    "num_states": 2,
    "network_type": "complete",
    "network_density": null,
    "safe_payoff": 0.5,
    "drift_rates": [
      0,
      1
    ],
    "jump_rates": [
      0,
      0.1
    ],
    "jump_sizes": [
      1.0,
      1.0
    ],
    "background_informativeness": 0.0,
    "diffusion_sigma": 0.0,
    "time_step": 1.0
  }
}